{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc32983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data中元素是否为空值的布尔型DataFrame为：\n",
      "       x1     x2     x3     x4     x5\n",
      "0  False  False  False  False  False\n",
      "1  False   True  False  False   True\n",
      "2  False  False   True  False  False\n",
      "3   True  False  False  False   True\n",
      "4  False   True  False  False  False\n",
      "5  False  False  False  False   True\n",
      "6  False  False   True  False  False\n",
      "data中元素是否为非空值的布尔型DataFrame为：\n",
      "       x1     x2     x3    x4     x5\n",
      "0   True   True   True  True   True\n",
      "1   True  False   True  True  False\n",
      "2   True   True  False  True   True\n",
      "3  False   True   True  True  False\n",
      "4   True  False   True  True   True\n",
      "5   True   True   True  True  False\n",
      "6   True   True  False  True   True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel('../data/data.xlsx')\n",
    "print('data中元素是否为空值的布尔型DataFrame为：\\n', data.isnull())\n",
    "print('data中元素是否为非空值的布尔型DataFrame为：\\n', data.notnull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be9e20ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data中每个特征对应的非空值数为：\n",
      " x1    6\n",
      "x2    5\n",
      "x3    5\n",
      "x4    7\n",
      "x5    4\n",
      "dtype: int64\n",
      "data中每个特征对应的缺失率为：\n",
      " x1    0.142857\n",
      "x2    0.285714\n",
      "x3    0.285714\n",
      "x4    0.000000\n",
      "x5    0.428571\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('data中每个特征对应的非空值数为：\\n', data.count())\n",
    "print('data中每个特征对应的缺失率为：\\n', 1-data.count() / len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b9b46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "箱型图的四分位距（IQR）检测出的array中异常值为：\n",
      " [376.04, 459.38, 1100.34, 2000.67]\n",
      "箱型图的四分位距（IQR）检测出的异常值比例为：\n",
      " 0.14814814814814814\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = (18.02, 63.77, 79.52, 29.89, 68.86, 54.49, 92.59, 376.04, 5.92, 83.75, 70.12, 459.38,\n",
    "       82.96, 37.81, 65.08, 59.07, 47.56, 86.96, 38.38, 1100.34, 7.98, 2.82, 74.76, 87.64,\n",
    "       67.90, 89.9, 2000.67)\n",
    "# 利用箱型图的四分位距（IQR）对异常值进行检测\n",
    "Percentile = np.percentile(arr, [0, 25, 50, 75, 100])  # 计算百分位数\n",
    "IQR = Percentile[3] - Percentile[1]  # 计算箱型图四分位距\n",
    "UpLimit = Percentile[3] + IQR*1.5  # 计算临界值上界\n",
    "arrayownLimit = Percentile[1] - IQR * 1.5  # 计算临界值下界\n",
    "# 判断异常值，大于上界或小于下界的值即为异常值\n",
    "abnormal = [i for i in arr if i > UpLimit or i < arrayownLimit] \n",
    "print('箱型图的四分位距（IQR）检测出的array中异常值为：\\n', abnormal)\n",
    "print('箱型图的四分位距（IQR）检测出的异常值比例为：\\n', len(abnormal) / len(arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78434235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3sigma原则检测出的array中异常值为：\n",
      " [1100.34, 2000.67]\n",
      "3sigma原则检测出的异常值比例为：\n",
      " 0.07407407407407407\n"
     ]
    }
   ],
   "source": [
    "# 利用3sigma原则对异常值进行检测\n",
    "array_mean = np.array(arr).mean()  # 计算平均值\n",
    "array_sarray = np.array(arr).std()  # 计算标准差\n",
    "array_cha = arr - array_mean  # 计算元素与平均值之差\n",
    "# 返回异常值所在位置\n",
    "ind = [i for i in range(len(array_cha)) if np.abs(array_cha[i]) > array_sarray]\n",
    "abnormal = [arr[i] for i in ind]  # 返回异常值\n",
    "print('3sigma原则检测出的array中异常值为：\\n', abnormal)\n",
    "print('3sigma原则检测出的异常值比例为：\\n', len(abnormal) / len(arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4131843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/hchsygq14tzfsjn6c4ybf3rh0000gn/T/ipykernel_12489/271471018.py:1: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data1 = pd.read_csv('../data/销售流水记录1.csv', encoding='gb18030')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前商品总数为： 611200\n",
      "使用列表（list）去重后商品的总数为： 10427\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data1 = pd.read_csv('../data/销售流水记录1.csv', encoding='gb18030')\n",
    "# 使用列表（list）去重\n",
    "# 定义去重函数\n",
    "def delRep(list1):\n",
    "    list2 = []\n",
    "    for i in list1:\n",
    "        if i not in list2:\n",
    "            list2.append(i)\n",
    "    return list2 \n",
    "# 去重\n",
    "sku_names = list(data1['sku_name'])  # 将sku_name从数据框中提取出来\n",
    "print('去重前商品总数为：', len(sku_names))\n",
    "sku_name = delRep(sku_names)  # 使用自定义的去重函数去重\n",
    "print('使用列表（list）去重后商品的总数为：', len(sku_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5af5e9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前商品总数为： 611200\n",
      "使用集合（set）重后商品总数为： 10427\n"
     ]
    }
   ],
   "source": [
    "# 使用集合（set）去重\n",
    "print('去重前商品总数为：', len(sku_names))\n",
    "sku_name_set = set(sku_names)  # 利用set的特性去重\n",
    "print('使用集合（set）重后商品总数为：', len(sku_name_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c92b1214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_duplicates方法去重之后商品总数为： 10427\n"
     ]
    }
   ],
   "source": [
    "# 使用drop_duplicates()方法对sku_name去重\n",
    "sku_name_pandas = data1['sku_name'].drop_duplicates()  # 对sku_name去重\n",
    "print('drop_duplicates方法去重之后商品总数为：', len(sku_name_pandas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4590ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重之前销售流水记录表的形状为： (611200, 10)\n",
      "依照订单编号，商品编号去重之后销售流水记录表大小为： (608176, 10)\n"
     ]
    }
   ],
   "source": [
    "# 使用drop_duplicates()方法对多列去重\n",
    "print('去重之前销售流水记录表的形状为：', data1.shape)\n",
    "shapeDet = data1.drop_duplicates(subset=['order_id', 'sku_id']).shape\n",
    "print('依照订单编号，商品编号去重之后销售流水记录表大小为：', shapeDet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf9479f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标价和卖价的kendall相似度为：\n",
      "                sku_prc  sku_sale_prc\n",
      "sku_prc       1.000000      0.900969\n",
      "sku_sale_prc  0.900969      1.000000\n"
     ]
    }
   ],
   "source": [
    "# 求取标价和卖价的相似度\n",
    "corrDet = data1[['sku_prc', 'sku_sale_prc']].corr(method='kendall')\n",
    "print('标价和卖价的kendall相似度为：\\n', corrDet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c10bd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "商品名称，标价和卖价价的pearson相似度为：\n",
      "                sku_prc  sku_sale_prc\n",
      "sku_prc       1.000000      0.970264\n",
      "sku_sale_prc  0.970264      1.000000\n"
     ]
    }
   ],
   "source": [
    "# 求出sku_name,sku_prc,sku_sale_prc三个特征的相似度\n",
    "corrDet1 = data1[['sku_name', 'sku_prc', 'sku_sale_prc']].corr(method='pearson')\n",
    "print('商品名称，标价和卖价价的pearson相似度为：\\n', corrDet1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f847e745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1的特征相等矩阵的前5行5列为：\n",
      "             create_dt order_id sku_id sku_name is_finished\n",
      "create_dt        True    False  False    False       False\n",
      "order_id        False     True  False    False       False\n",
      "sku_id          False    False   True    False       False\n",
      "sku_name        False    False  False     True       False\n",
      "is_finished     False    False  False    False        True\n"
     ]
    }
   ],
   "source": [
    "# 使用DataFrame.equals()进行特征去重\n",
    "def FeatureEquals(df):\n",
    "    dfEquals = pd.DataFrame([], columns=df.columns, index=df.columns)\n",
    "    for i in df.columns:\n",
    "       for j in df.columns:\n",
    "           dfEquals.loc[i, j] = df.loc[: , i].equals(df.loc[: , j])\n",
    "    return dfEquals\n",
    "# 应用上述函数\n",
    "detEquals = FeatureEquals(data1)\n",
    "print('data1的特征相等矩阵的前5行5列为：\\n', detEquals.iloc[: 5, : 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd58bac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要删除的列为： []\n",
      "删除多余列后detail的特征数目为： 10\n"
     ]
    }
   ],
   "source": [
    "# 遍历所有数据\n",
    "lenDet = detEquals.shape[0]\n",
    "dupCol = []\n",
    "for k in range(lenDet):\n",
    "    for l in range(k+1, lenDet):\n",
    "        if detEquals.iloc[k, l] & (detEquals.columns[l] not in dupCol):\n",
    "            dupCol.append(detEquals.columns[l])\n",
    "# 进行去重操作\n",
    "print('需要删除的列为：', dupCol)\n",
    "data1.drop(dupCol, axis=1, inplace=True)\n",
    "print('删除多余列后detail的特征数目为：', data1.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b9806a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去除含缺失的列前detail的形状为： (611200, 10)\n",
      "去除含缺失的列后detail的形状为： (611200, 9)\n"
     ]
    }
   ],
   "source": [
    "# 使用dropna()方法删除缺失值\n",
    "print('去除含缺失的列前detail的形状为：', data1.shape)\n",
    "print('去除含缺失的列后detail的形状为：', data1.dropna(axis=1, how='any').shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28f690c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datal每个特征缺失的数目为：\n",
      " create_dt       0\n",
      "order_id        0\n",
      "sku_id          0\n",
      "sku_name        0\n",
      "is_finished     0\n",
      "sku_cnt         0\n",
      "sku_prc         0\n",
      "sku_sale_prc    0\n",
      "sku_cost_prc    0\n",
      "upc_code        0\n",
      "dtype: int64\n",
      "datal每个特征缺失的数目为：\n",
      " create_dt       0\n",
      "order_id        0\n",
      "sku_id          0\n",
      "sku_name        0\n",
      "is_finished     0\n",
      "sku_cnt         0\n",
      "sku_prc         0\n",
      "sku_sale_prc    0\n",
      "sku_cost_prc    0\n",
      "upc_code        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 使用filena()方法替换缺失值\n",
    "print('datal每个特征缺失的数目为：\\n', data1.isnull().sum())\n",
    "data1 = data1.fillna(-99)\n",
    "print('datal每个特征缺失的数目为：\\n', data1.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a09f904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当x为3、7、9时，使用线性插值y1为： [  73.  729. 1513.]\n",
      "当x为3、7、9时，使用线性插值y2为： [11. 23. 29.]\n"
     ]
    }
   ],
   "source": [
    "# 线性插值\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "x = np.array([1, 2, 4, 5, 6, 8, 10])  # 创建自变量x\n",
    "y1 = np.array([3, 17, 129, 251, 433, 1025, 2001])  # 创建因变量y1\n",
    "y2 = np.array([5, 8, 14, 17, 20, 26, 32])  # 创建因变量y2\n",
    "LinearInsValue1 = interp1d(x, y1, kind='linear')  # 线性插值拟合x, y1\n",
    "LinearInsValue2 = interp1d(x, y2, kind='linear')  # 线性插值拟合x, y2\n",
    "print('当x为3、7、9时，使用线性插值y1为：', LinearInsValue1([3, 7, 9]))\n",
    "print('当x为3、7、9时，使用线性插值y2为：', LinearInsValue2([3, 7, 9]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b805fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当x为3、7、9时，使用拉格朗日插值y1为： [  55.  687. 1459.]\n",
      "当x为3、7、9时，使用拉格朗日插值y2为： [11. 23. 29.]\n"
     ]
    }
   ],
   "source": [
    "# 拉格朗日插值\n",
    "from scipy.interpolate import lagrange\n",
    "LargeInsValue1 = lagrange(x, y1)  # 拉格朗日插值拟合x, y1\n",
    "LargeInsValue2 = lagrange(x, y2)  # 拉格朗日插值拟合x, y2\n",
    "print('当x为3、7、9时，使用拉格朗日插值y1为：', LargeInsValue1([3, 7, 9]))\n",
    "print('当x为3、7、9时，使用拉格朗日插值y2为：', LargeInsValue2([3, 7, 9]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60aa4618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当x为3、7、9时，使用样条插值y1为： [  55.  687. 1459.]\n",
      "当x为3、7、9时，使用样条插值y2为： [11. 23. 29.]\n"
     ]
    }
   ],
   "source": [
    "# 样条插值\n",
    "from scipy.interpolate import splrep, splev\n",
    "tck1 = splrep(x, y1)\n",
    "x_new = np.array([3, 7, 9])\n",
    "SplineInsValue1 = splev(x_new, tck1)  # 样条插值拟合x, y1\n",
    "tck2 = splrep(x, y2)\n",
    "SplineInsValue2 = splev(x_new, tck2)  # 样条插值拟合x, y2\n",
    "print('当x为3、7、9时，使用样条插值y1为：', SplineInsValue1)\n",
    "print('当x为3、7、9时，使用样条插值y2为：', SplineInsValue2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "243e6f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内连接合并后的数据框为：\n",
      "     A   B   C   D   B   D   F\n",
      "2  A2  B2  C2  D2  B2  D2  F2\n",
      "4  A4  B4  C4  D4  B4  D4  F4\n",
      "外连接合并后的数据框为：\n",
      "      A    B    C    D    B    D    F\n",
      "1   A1   B1   C1   D1  NaN  NaN  NaN\n",
      "2   A2   B2   C2   D2   B2   D2   F2\n",
      "3   A3   B3   C3   D3  NaN  NaN  NaN\n",
      "4   A4   B4   C4   D4   B4   D4   F4\n",
      "6  NaN  NaN  NaN  NaN   B6   D6   F6\n",
      "8  NaN  NaN  NaN  NaN   B8   D8   F8\n"
     ]
    }
   ],
   "source": [
    "# 索引完全相同时使用concat函数横向堆叠\n",
    "import pandas as pd\n",
    "# 创建数据\n",
    "data1 = pd.DataFrame({\n",
    "    'A': ['A1', 'A2', 'A3', 'A4'], 'B': ['B1', 'B2', 'B3', 'B4'], 'C': ['C1', 'C2','C3', 'C4'],\n",
    "    'D': ['D1', 'D2', 'D3', 'D4']}, index=[1, 2, 3, 4])\n",
    "data2 = pd.DataFrame({\n",
    "    'B': ['B2', 'B4', 'B6', 'B8'], 'D': ['D2', 'D4', 'D6', 'D8'], 'F': ['F2', 'F4','F6', 'F8']},\n",
    "    index=[2, 4, 6, 8])\n",
    "print('内连接合并后的数据框为：\\n', pd.concat([data1, data2], axis=1, join='inner'))\n",
    "print('外连接合并后的数据框为：\\n', pd.concat([data1, data2], axis=1, join='outer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a9fd52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内连接纵向合并后的数据框为：\n",
      "     B   D\n",
      "1  B1  D1\n",
      "2  B2  D2\n",
      "3  B3  D3\n",
      "4  B4  D4\n",
      "2  B2  D2\n",
      "4  B4  D4\n",
      "6  B6  D6\n",
      "8  B8  D8\n",
      "外连接纵向合并后的数据框为：\n",
      "      A   B    C   D    F\n",
      "1   A1  B1   C1  D1  NaN\n",
      "2   A2  B2   C2  D2  NaN\n",
      "3   A3  B3   C3  D3  NaN\n",
      "4   A4  B4   C4  D4  NaN\n",
      "2  NaN  B2  NaN  D2   F2\n",
      "4  NaN  B4  NaN  D4   F4\n",
      "6  NaN  B6  NaN  D6   F6\n",
      "8  NaN  B8  NaN  D8   F8\n"
     ]
    }
   ],
   "source": [
    "# 表名完全相同时使用concat函数纵向堆叠\n",
    "print('内连接纵向合并后的数据框为：\\n', pd.concat([data1, data2], axis=0, join='inner'))\n",
    "print('外连接纵向合并后的数据框为：\\n', pd.concat([data1, data2], axis=0, join='outer'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cf8e86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/hchsygq14tzfsjn6c4ybf3rh0000gn/T/ipykernel_12489/2243234962.py:2: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data1 = pd.read_csv('../data/销售流水记录1.csv', encoding='gb18030')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "堆叠前data1数据框的大小： (611200, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/hchsygq14tzfsjn6c4ybf3rh0000gn/T/ipykernel_12489/2243234962.py:4: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data2 = pd.read_csv('../data/销售流水记录2.csv', encoding='gb18030')\n",
      "/var/folders/kd/hchsygq14tzfsjn6c4ybf3rh0000gn/T/ipykernel_12489/2243234962.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  print('append纵向堆叠后的数据框大小为：', data1.append(data2).shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "堆叠前data2数据框的大小： (610655, 10)\n",
      "append纵向堆叠后的数据框大小为： (1221855, 10)\n"
     ]
    }
   ],
   "source": [
    "# 使用append()方法纵向表堆叠\n",
    "data1 = pd.read_csv('../data/销售流水记录1.csv', encoding='gb18030')\n",
    "print('堆叠前data1数据框的大小：', data1.shape)\n",
    "data2 = pd.read_csv('../data/销售流水记录2.csv', encoding='gb18030')\n",
    "print('堆叠前data2数据框的大小：', data2.shape)\n",
    "print('append纵向堆叠后的数据框大小为：', data1.append(data2).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d470236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销售流水记录表的原始形状为： (611200, 10)\n",
      "商品信息表的原始形状为： (6570, 8)\n",
      "销售流水记录表和商品信息表主键合并后的形状为： (611111, 17)\n"
     ]
    }
   ],
   "source": [
    "# 使用merge()函数合并数据\n",
    "import pandas as pd\n",
    "data1 = pd.read_csv('../data/销售流水记录1.csv', encoding='gb18030', low_memory=False)\n",
    "print('销售流水记录表的原始形状为：', data1.shape)\n",
    "goods_info = pd.read_excel('../data/商品信息表.xlsx')\n",
    "print('商品信息表的原始形状为：', goods_info.shape)\n",
    "sale_detail = pd.merge(data1, goods_info, on='sku_id')\n",
    "print('销售流水记录表和商品信息表主键合并后的形状为：', sale_detail.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59c8d134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销售流水记录表和商品信息表join合并后的形状为： (611200, 18)\n"
     ]
    }
   ],
   "source": [
    "# 使用join()方法实现主键合并\n",
    "sale_detail2 = data1.join(goods_info, on='sku_id', rsuffix='1')\n",
    "print('销售流水记录表和商品信息表join合并后的形状为：', sale_detail2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80e0117e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df1.combine_first(df2)的结果：\n",
      "      a    b    c\n",
      "0  2.0  NaN  1.0\n",
      "1  2.0  6.0  3.0\n",
      "2  1.0  5.0  5.0\n",
      "3  1.0  8.0  7.0\n",
      "4  8.0  9.0  NaN\n",
      "\n",
      "df2.combine_first(df1)的结果：\n",
      "      a    b    c\n",
      "0  6.0  NaN  1.0\n",
      "1  2.0  2.0  3.0\n",
      "2  1.0  5.0  5.0\n",
      "3  1.0  8.0  7.0\n",
      "4  8.0  9.0  NaN\n"
     ]
    }
   ],
   "source": [
    "# 重叠合并\n",
    "# 生成两个数据框\n",
    "df1 = pd.DataFrame({'a': [2., np.nan, 1., np.nan], 'b': [np.nan, 6., np.nan, 8.],\n",
    "'c': range(1, 8, 2)})\n",
    "df2 = pd.DataFrame({'a': [6., 2., np.nan, 1., 8.], 'b': [np.nan, 2., 5., 8., 9.]})\n",
    "# 采取不同的方式\n",
    "print('\\ndf1.combine_first(df2)的结果：\\n', df1.combine_first(df2))\n",
    "print('\\ndf2.combine_first(df1)的结果：\\n', df2.combine_first(df1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d7354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
