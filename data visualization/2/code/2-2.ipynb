{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9317d7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data中元素是否为空值的布尔型DataFrame为:\n",
      "       x1     x2     x3     x4     x5\n",
      "0  False  False  False  False  False\n",
      "1  False   True  False  False   True\n",
      "2  False  False   True  False  False\n",
      "3   True  False  False  False   True\n",
      "4  False   True  False  False  False\n",
      "5  False  False  False  False   True\n",
      "6  False  False   True  False  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel('../data/data.xlsx')\n",
    "print('data中元素是否为空值的布尔型DataFrame为:\\n',data.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b270ef27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data中元素是否为非空值的布尔型DataFrame为:\n",
      "       x1     x2     x3    x4     x5\n",
      "0   True   True   True  True   True\n",
      "1   True  False   True  True  False\n",
      "2   True   True  False  True   True\n",
      "3  False   True   True  True  False\n",
      "4   True  False   True  True   True\n",
      "5   True   True   True  True  False\n",
      "6   True   True  False  True   True\n"
     ]
    }
   ],
   "source": [
    "print('data中元素是否为非空值的布尔型DataFrame为:\\n',data.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e22ecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data中每个特征对应的非空值数为\n",
      " x1    6\n",
      "x2    5\n",
      "x3    5\n",
      "x4    7\n",
      "x5    4\n",
      "dtype: int64\n",
      "data中每个特征对应的缺失率为:\n",
      " x1    0.142857\n",
      "x2    0.285714\n",
      "x3    0.285714\n",
      "x4    0.000000\n",
      "x5    0.428571\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('data中每个特征对应的非空值数为\\n',data.count())\n",
    "print('data中每个特征对应的缺失率为:\\n',1-data.count()/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd926d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "箱线图的IQR准则检测出的array中异常值为:\n",
      " [376.04, 459.38, 1100.34, 2000.67]\n",
      "箱线图的IQR准则检测出异常值的比例为:\n",
      " 0.14814814814814814\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "arr = (18.02,63.77,79.52,29.89,68.86,54.49,92.59,376.04,5.92,\n",
    "       83.75,70.12,459.38,82.96,37.81,65.08,59.07,47.56,86.96,\n",
    "      38.38,1100.34,7.98,2.82,74.76,87.64,67.90,89.9,2000.67)\n",
    "# 利用箱线图的IQR准则对异常值进行检测\n",
    "Percentile = np.percentile(arr,[0,25,50,75,100])# 计算百分位数\n",
    "IQR = Percentile[3]-Percentile[1] # 计算箱线图IQR\n",
    "UpLimit = Percentile[3] + IQR * 1.5 # 计算临界值上界\n",
    "arrayownLimit = Percentile[1] - IQR *1.5 # 计算临界值的下界\n",
    "# 判断异常值,大于上界或者小于下界的值就是异常值\n",
    "abnormal = [i for i in arr if i > UpLimit or i < arrayownLimit]\n",
    "print('箱线图的IQR准则检测出的array中异常值为:\\n',abnormal)\n",
    "print('箱线图的IQR准则检测出异常值的比例为:\\n',len(abnormal)/len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "747a1ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3sigma原则检测出的array异常值为:\n",
      " [1100.34, 2000.67]\n",
      "3sigma原则检测出异常值的比例为:\n",
      " 0.07407407407407407\n"
     ]
    }
   ],
   "source": [
    "# 利用3sigma原则对异常值进行检测\n",
    "array_mean = np.array(arr).mean() # 计算平均值\n",
    "array_sarray = np.array(arr).std() # 计算标准差\n",
    "array_cha = arr - array_mean # 计算元素与平均值之差\n",
    "# 返回异常值所在位置\n",
    "ind = [i for i in range(len(array_cha)) if np.abs(array_cha[i]) > array_sarray]\n",
    "abnormal = [arr[i] for i in ind]\n",
    "print('3sigma原则检测出的array异常值为:\\n',abnormal)\n",
    "print('3sigma原则检测出异常值的比例为:\\n',len(abnormal) / len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0fe8df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前商品的总数为: 611200\n",
      "使用list(列表)去重后商品的总数为 10427\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv('../data/销售流水记录1.csv',encoding='gb18030',low_memory=False)\n",
    "# 使用列表(list)去重\n",
    "# 定义去重函数\n",
    "def delRep(list1):\n",
    "    list2 = []\n",
    "    for i in list1:\n",
    "        if i not in list2:\n",
    "            list2.append(i)\n",
    "    return list2\n",
    "# 去重\n",
    "sku_names = list(data1['sku_name']) # 将sku_name从数据框中提取出来\n",
    "print('去重前商品的总数为:',len(sku_names))\n",
    "sku_name = delRep(sku_names)\n",
    "print('使用list(列表)去重后商品的总数为',len(sku_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "614de067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前商品的总数为 611200\n",
      "使用集合(set)去重后商品的总数为: 10427\n"
     ]
    }
   ],
   "source": [
    "# 使用集合(set)去重\n",
    "print('去重前商品的总数为',len(sku_names))\n",
    "sku_name_set = set(sku_names) # 利用set的特性去重\n",
    "print('使用集合(set)去重后商品的总数为:',len(sku_name_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc916b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_duplicates方法去重之后商品总数为: 10427\n"
     ]
    }
   ],
   "source": [
    "# 使用drop_duplicates()方法对sku_names去重\n",
    "sku_name_pandas = data1['sku_name'].drop_duplicates()\n",
    "print('drop_duplicates方法去重之后商品总数为:',len(sku_name_pandas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa56aed3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重之前销售流水记录表的形状为: (611200, 10)\n",
      "依照订单编号,商品编号去重之后销售流水记录表大小为: (608176, 10)\n"
     ]
    }
   ],
   "source": [
    "# 使用drop_duplicates()对多列去重\n",
    "print('去重之前销售流水记录表的形状为:',data1.shape)\n",
    "shapeDet = data1.drop_duplicates(subset=['order_id','sku_id']).shape\n",
    "print('依照订单编号,商品编号去重之后销售流水记录表大小为:',shapeDet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baf137e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标价和卖价的kendall相似度为:\n",
      "                sku_prc  sku_sale_prc\n",
      "sku_prc       1.000000      0.900969\n",
      "sku_sale_prc  0.900969      1.000000\n"
     ]
    }
   ],
   "source": [
    "# 求标价和卖价的相似度\n",
    "corrDet = data1[['sku_prc','sku_sale_prc']].corr(method='kendall')\n",
    "print('标价和卖价的kendall相似度为:\\n',corrDet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aa1105f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "商品名称,标价,卖价三者的pearson相似度为:\n",
      "                sku_prc  sku_sale_prc\n",
      "sku_prc       1.000000      0.970264\n",
      "sku_sale_prc  0.970264      1.000000\n"
     ]
    }
   ],
   "source": [
    "# 求标价,卖价,名称三个特征之间的相似度\n",
    "corrDet1 = data1[['sku_prc','sku_sale_prc','sku_name']].corr(method='pearson')\n",
    "print('商品名称,标价,卖价三者的pearson相似度为:\\n',corrDet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ebd6c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1的特征相等矩阵的前5行5列:\n",
      "             create_dt order_id sku_id sku_name is_finished\n",
      "create_dt        True    False  False    False       False\n",
      "order_id        False     True  False    False       False\n",
      "sku_id          False    False   True    False       False\n",
      "sku_name        False    False  False     True       False\n",
      "is_finished     False    False  False    False        True\n"
     ]
    }
   ],
   "source": [
    "# 使用DataFrame.equals()进行特征去重\n",
    "# 定义检验特征是否完全相同的矩阵的函数\n",
    "def FeatureEquals(df):\n",
    "    dfEquals = pd.DataFrame([],columns=df.columns,index=df.columns)\n",
    "    for i in df.columns:\n",
    "        for j in df.columns:\n",
    "            dfEquals.loc[i,j] = df.loc[: ,i].equals(df.loc[: ,j])\n",
    "    return dfEquals\n",
    "# 应用上述函数\n",
    "detEquals = FeatureEquals(data1)\n",
    "print('data1的特征相等矩阵的前5行5列:\\n',detEquals.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfd08cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要删除的列为 []\n",
      "删除多余列后detail得特征数目为: 10\n"
     ]
    }
   ],
   "source": [
    "# 遍历所有数据\n",
    "lenDet = detEquals.shape[0]\n",
    "dupCol = []\n",
    "for k in range(lenDet):\n",
    "    for l in range(k+1,lenDet):\n",
    "        if detEquals.iloc[k,l] & (detEquals.columns[l] not in dupCol):\n",
    "            dupCol.append(detEquals.columns[l])\n",
    "# 进行去重操作\n",
    "print('需要删除的列为',dupCol)\n",
    "data1.drop(dupCol,axis=1,inplace=True)\n",
    "print('删除多余列后detail得特征数目为:',data1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c3bed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
