{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9317d7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data中元素是否为空值的布尔型DataFrame为:\n",
      "       x1     x2     x3     x4     x5\n",
      "0  False  False  False  False  False\n",
      "1  False   True  False  False   True\n",
      "2  False  False   True  False  False\n",
      "3   True  False  False  False   True\n",
      "4  False   True  False  False  False\n",
      "5  False  False  False  False   True\n",
      "6  False  False   True  False  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel('../data/data.xlsx')\n",
    "print('data中元素是否为空值的布尔型DataFrame为:\\n',data.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b270ef27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data中元素是否为非空值的布尔型DataFrame为:\n",
      "       x1     x2     x3    x4     x5\n",
      "0   True   True   True  True   True\n",
      "1   True  False   True  True  False\n",
      "2   True   True  False  True   True\n",
      "3  False   True   True  True  False\n",
      "4   True  False   True  True   True\n",
      "5   True   True   True  True  False\n",
      "6   True   True  False  True   True\n"
     ]
    }
   ],
   "source": [
    "print('data中元素是否为非空值的布尔型DataFrame为:\\n',data.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e22ecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data中每个特征对应的非空值数为\n",
      " x1    6\n",
      "x2    5\n",
      "x3    5\n",
      "x4    7\n",
      "x5    4\n",
      "dtype: int64\n",
      "data中每个特征对应的缺失率为:\n",
      " x1    0.142857\n",
      "x2    0.285714\n",
      "x3    0.285714\n",
      "x4    0.000000\n",
      "x5    0.428571\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('data中每个特征对应的非空值数为\\n',data.count())\n",
    "print('data中每个特征对应的缺失率为:\\n',1-data.count()/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd926d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "箱线图的IQR准则检测出的array中异常值为:\n",
      " [376.04, 459.38, 1100.34, 2000.67]\n",
      "箱线图的IQR准则检测出异常值的比例为:\n",
      " 0.14814814814814814\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "arr = (18.02,63.77,79.52,29.89,68.86,54.49,92.59,376.04,5.92,\n",
    "       83.75,70.12,459.38,82.96,37.81,65.08,59.07,47.56,86.96,\n",
    "      38.38,1100.34,7.98,2.82,74.76,87.64,67.90,89.9,2000.67)\n",
    "# 利用箱线图的IQR准则对异常值进行检测\n",
    "Percentile = np.percentile(arr,[0,25,50,75,100])# 计算百分位数\n",
    "IQR = Percentile[3]-Percentile[1] # 计算箱线图IQR\n",
    "UpLimit = Percentile[3] + IQR * 1.5 # 计算临界值上界\n",
    "arrayownLimit = Percentile[1] - IQR *1.5 # 计算临界值的下界\n",
    "# 判断异常值,大于上界或者小于下界的值就是异常值\n",
    "abnormal = [i for i in arr if i > UpLimit or i < arrayownLimit]\n",
    "print('箱线图的IQR准则检测出的array中异常值为:\\n',abnormal)\n",
    "print('箱线图的IQR准则检测出异常值的比例为:\\n',len(abnormal)/len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "747a1ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3sigma原则检测出的array异常值为:\n",
      " [1100.34, 2000.67]\n",
      "3sigma原则检测出异常值的比例为:\n",
      " 0.07407407407407407\n"
     ]
    }
   ],
   "source": [
    "# 利用3sigma原则对异常值进行检测\n",
    "array_mean = np.array(arr).mean() # 计算平均值\n",
    "array_sarray = np.array(arr).std() # 计算标准差\n",
    "array_cha = arr - array_mean # 计算元素与平均值之差\n",
    "# 返回异常值所在位置\n",
    "ind = [i for i in range(len(array_cha)) if np.abs(array_cha[i]) > array_sarray]\n",
    "abnormal = [arr[i] for i in ind]\n",
    "print('3sigma原则检测出的array异常值为:\\n',abnormal)\n",
    "print('3sigma原则检测出异常值的比例为:\\n',len(abnormal) / len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fe8df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前商品的总数为: 611200\n",
      "使用list(列表)去重后商品的总数为 10427\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv('../data/销售流水记录1.csv',encoding='gb18030',low_memory=False)\n",
    "# 使用列表(list)去重\n",
    "# 定义去重函数\n",
    "def delRep(list1):\n",
    "    list2 = []\n",
    "    for i in list1:\n",
    "        if i not in list2:\n",
    "            list2.append(i)\n",
    "    return list2\n",
    "# 去重\n",
    "sku_names = list(data1['sku_name']) # 将sku_name从数据框中提取出来\n",
    "print('去重前商品的总数为:',len(sku_names))\n",
    "sku_name = delRep(sku_names)\n",
    "print('使用list(列表)去重后商品的总数为',len(sku_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "614de067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前商品的总数为 611200\n",
      "使用集合(set)去重后商品的总数为: 10427\n"
     ]
    }
   ],
   "source": [
    "# 使用集合(set)去重\n",
    "print('去重前商品的总数为',len(sku_names))\n",
    "sku_name_set = set(sku_names) # 利用set的特性去重\n",
    "print('使用集合(set)去重后商品的总数为:',len(sku_name_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc916b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_duplicates方法去重之后商品总数为: 10427\n"
     ]
    }
   ],
   "source": [
    "# 使用drop_duplicates()方法对sku_names去重\n",
    "sku_name_pandas = data1['sku_name'].drop_duplicates()\n",
    "print('drop_duplicates方法去重之后商品总数为:',len(sku_name_pandas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa56aed3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重之前销售流水记录表的形状为: (611200, 10)\n",
      "依照订单编号,商品编号去重之后销售流水记录表大小为: (608176, 10)\n"
     ]
    }
   ],
   "source": [
    "# 使用drop_duplicates()对多列去重\n",
    "print('去重之前销售流水记录表的形状为:',data1.shape)\n",
    "shapeDet = data1.drop_duplicates(subset=['order_id','sku_id']).shape\n",
    "print('依照订单编号,商品编号去重之后销售流水记录表大小为:',shapeDet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baf137e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标价和卖价的kendall相似度为:\n",
      "                sku_prc  sku_sale_prc\n",
      "sku_prc       1.000000      0.900969\n",
      "sku_sale_prc  0.900969      1.000000\n"
     ]
    }
   ],
   "source": [
    "# 求标价和卖价的相似度\n",
    "corrDet = data1[['sku_prc','sku_sale_prc']].corr(method='kendall')\n",
    "print('标价和卖价的kendall相似度为:\\n',corrDet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aa1105f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "商品名称,标价,卖价三者的pearson相似度为:\n",
      "                sku_prc  sku_sale_prc\n",
      "sku_prc       1.000000      0.970264\n",
      "sku_sale_prc  0.970264      1.000000\n"
     ]
    }
   ],
   "source": [
    "# 求标价,卖价,名称三个特征之间的相似度\n",
    "corrDet1 = data1[['sku_prc','sku_sale_prc','sku_name']].corr(method='pearson')\n",
    "print('商品名称,标价,卖价三者的pearson相似度为:\\n',corrDet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ebd6c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1的特征相等矩阵的前5行5列:\n",
      "             create_dt order_id sku_id sku_name is_finished\n",
      "create_dt        True    False  False    False       False\n",
      "order_id        False     True  False    False       False\n",
      "sku_id          False    False   True    False       False\n",
      "sku_name        False    False  False     True       False\n",
      "is_finished     False    False  False    False        True\n"
     ]
    }
   ],
   "source": [
    "# 使用DataFrame.equals()进行特征去重\n",
    "# 定义检验特征是否完全相同的矩阵的函数\n",
    "def FeatureEquals(df):\n",
    "    dfEquals = pd.DataFrame([],columns=df.columns,index=df.columns)\n",
    "    for i in df.columns:\n",
    "        for j in df.columns:\n",
    "            dfEquals.loc[i,j] = df.loc[: ,i].equals(df.loc[: ,j])\n",
    "    return dfEquals\n",
    "# 应用上述函数\n",
    "detEquals = FeatureEquals(data1)\n",
    "print('data1的特征相等矩阵的前5行5列:\\n',detEquals.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfd08cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要删除的列为 []\n",
      "删除多余列后detail得特征数目为: 10\n"
     ]
    }
   ],
   "source": [
    "# 遍历所有数据\n",
    "lenDet = detEquals.shape[0]\n",
    "dupCol = []\n",
    "for k in range(lenDet):\n",
    "    for l in range(k+1,lenDet):\n",
    "        if detEquals.iloc[k,l] & (detEquals.columns[l] not in dupCol):\n",
    "            dupCol.append(detEquals.columns[l])\n",
    "# 进行去重操作\n",
    "print('需要删除的列为',dupCol)\n",
    "data1.drop(dupCol,axis=1,inplace=True)\n",
    "print('删除多余列后detail得特征数目为:',data1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "086c3bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去除含缺失值的列前detail的形状为 (611200, 10)\n",
      "去除含缺失值的列后detail的形状为 (611200, 9)\n"
     ]
    }
   ],
   "source": [
    "print('去除含缺失值的列前detail的形状为',data1.shape)\n",
    "print('去除含缺失值的列后detail的形状为',data1.dropna(axis=1,how='any').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bc4623f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1每个特征缺失的数目为:\n",
      " create_dt           0\n",
      "order_id            0\n",
      "sku_id              0\n",
      "sku_name            0\n",
      "is_finished         0\n",
      "sku_cnt             0\n",
      "sku_prc             0\n",
      "sku_sale_prc        0\n",
      "sku_cost_prc        0\n",
      "upc_code        15895\n",
      "dtype: int64\n",
      "data1每个特征值缺失的数目为;\n",
      " create_dt       0\n",
      "order_id        0\n",
      "sku_id          0\n",
      "sku_name        0\n",
      "is_finished     0\n",
      "sku_cnt         0\n",
      "sku_prc         0\n",
      "sku_sale_prc    0\n",
      "sku_cost_prc    0\n",
      "upc_code        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 使用fillna()方法替换缺失值\n",
    "data1.isnull().sum()\n",
    "print('data1每个特征缺失的数目为:\\n',data1.isnull().sum())\n",
    "data1 = data1.fillna(-99)\n",
    "print('data1每个特征值缺失的数目为;\\n',data1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7e6be96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当x为3、7、9时,使用线性插值y1为 [  73.  729. 1513.]\n",
      "当x为3、7、9时,使用线性插值y2为 [11. 23. 29.]\n"
     ]
    }
   ],
   "source": [
    "# 线性插值\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "x = np.array([1,2,4,5,6,8,10])#创建自变量x\n",
    "y1 = np.array([3,17,129,251,433,1025,2001])#创建因变量y1\n",
    "y2 = np.array([5,8,14,17,20,26,32])#创建因变量y2\n",
    "LinearInsValue1 = interp1d(x,y1,kind='linear') #线性插值拟合x,y1\n",
    "LinearInsValue2 = interp1d(x,y2,kind='linear') #线性插值拟合x,y2\n",
    "print('当x为3、7、9时,使用线性插值y1为',LinearInsValue1([3,7,9]))\n",
    "print('当x为3、7、9时,使用线性插值y2为',LinearInsValue2([3,7,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "342a9be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当x为3、7、9时,使用拉格朗日插值y1为 [  55.  687. 2663.]\n",
      "当x为3、7、9时,使用拉格朗日插值y2为 [11. 23. 35.]\n"
     ]
    }
   ],
   "source": [
    "# 拉格朗日插值\n",
    "from scipy.interpolate import lagrange\n",
    "LargeInsValue1 = lagrange(x,y1) #拉格朗日拟合x,y1\n",
    "LargeInsValue2 = lagrange(x,y2) #拉格朗日拟合x,y2\n",
    "print('当x为3、7、9时,使用拉格朗日插值y1为',LargeInsValue1([3,7,11]))\n",
    "print('当x为3、7、9时,使用拉格朗日插值y2为',LargeInsValue2([3,7,11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11850618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当x为3、7、9时,使用样条插值y1为: [  55.  687. 1459.]\n",
      "当x为3、7、9时,使用样条插值y2为: [11. 23. 29.]\n"
     ]
    }
   ],
   "source": [
    "# 样条插值\n",
    "from scipy.interpolate import splrep,splev\n",
    "tck1 = splrep(x,y1)\n",
    "x_new = np.array([3,7,9])\n",
    "SplineInsValue1 = splev(x_new,tck1) # 样条插值拟合x,y1\n",
    "tck2 = splrep(x,y2)\n",
    "SplineInsValue2 = splev(x_new,tck2) # 样条插值拟合x,y2\n",
    "print('当x为3、7、9时,使用样条插值y1为:',SplineInsValue1)\n",
    "print('当x为3、7、9时,使用样条插值y2为:',SplineInsValue2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e225aa59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "4  A4  B4  C4  D4\n",
      "    B   D   F\n",
      "2  B2  D2  F2\n",
      "4  B4  D4  F4\n",
      "6  B6  D6  F6\n",
      "8  B8  D8  F8\n",
      "内连接合并后的数据框为:\n",
      "     A   B   C   D   B   D   F\n",
      "2  A2  B2  C2  D2  B2  D2  F2\n",
      "4  A4  B4  C4  D4  B4  D4  F4\n",
      "外连接合并后怒的数据框为:\n",
      "      A    B    C    D    B    D    F\n",
      "1   A1   B1   C1   D1  NaN  NaN  NaN\n",
      "2   A2   B2   C2   D2   B2   D2   F2\n",
      "3   A3   B3   C3   D3  NaN  NaN  NaN\n",
      "4   A4   B4   C4   D4   B4   D4   F4\n",
      "6  NaN  NaN  NaN  NaN   B6   D6   F6\n",
      "8  NaN  NaN  NaN  NaN   B8   D8   F8\n"
     ]
    }
   ],
   "source": [
    "# 索引完全相同时使用concat函数进行横向堆叠\n",
    "import pandas as pd\n",
    "# 创建数据\n",
    "data1 = pd.DataFrame({\n",
    "    'A':['A1','A2','A3','A4'],'B':['B1','B2','B3','B4'],'C':['C1','C2','C3','C4'],'D':['D1','D2','D3','D4']\n",
    "},index=[1,2,3,4])\n",
    "data2 = pd.DataFrame({\n",
    "    'B':['B2','B4','B6','B8'],'D':['D2','D4','D6','D8'],'F':['F2','F4','F6','F8']\n",
    "},index=[2,4,6,8])\n",
    "print(data1)\n",
    "print(data2)\n",
    "print('内连接合并后的数据框为:\\n',pd.concat([data1,data2],axis=1,join='inner'))\n",
    "print('外连接合并后怒的数据框为:\\n',pd.concat([data1,data2],axis=1,join='outer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a0e1448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内连接纵向合并后的数据框位:\n",
      "     B   D\n",
      "1  B1  D1\n",
      "2  B2  D2\n",
      "3  B3  D3\n",
      "4  B4  D4\n",
      "2  B2  D2\n",
      "4  B4  D4\n",
      "6  B6  D6\n",
      "8  B8  D8\n",
      "外连接纵向合并后的数据框为:\n",
      "      A   B    C   D    F\n",
      "1   A1  B1   C1  D1  NaN\n",
      "2   A2  B2   C2  D2  NaN\n",
      "3   A3  B3   C3  D3  NaN\n",
      "4   A4  B4   C4  D4  NaN\n",
      "2  NaN  B2  NaN  D2   F2\n",
      "4  NaN  B4  NaN  D4   F4\n",
      "6  NaN  B6  NaN  D6   F6\n",
      "8  NaN  B8  NaN  D8   F8\n"
     ]
    }
   ],
   "source": [
    "print('内连接纵向合并后的数据框位:\\n',pd.concat([data1,data2],axis=0,join='inner'))\n",
    "print('外连接纵向合并后的数据框为:\\n',pd.concat([data1,data2],axis=0,join='outer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bbef98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "堆叠前data1数据框的大小: (611200, 10)\n",
      "堆叠前data2数据框的大小: (610655, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.read_csv('../data/销售流水记录1.csv',encoding='gb18030',low_memory=False)\n",
    "print('堆叠前data1数据框的大小:',data1.shape)\n",
    "data2 = pd.read_csv('../data/销售流水记录2.csv',encoding='gb18030',low_memory=False)\n",
    "print('堆叠前data2数据框的大小:',data2.shape)\n",
    "print('append纵向堆叠后数据框的大小为:'data1.append(data2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ac85b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
